*** To-do's
**** SCPN framework
***** TODO port SCPN code from python2 to python3 and ensure it works, if not re-train model for python 3 -> priority is for generate_paraphrases.py first to check if the saved models can work, might need to port other linking files as well
***** download stanford parser into repo and use this on WMT 17 data
***** generate parses for WMT17 dev/test, check quality and think of how to extend this utility to other SOTA parsers
***** generate paraphrases for WMT 17 data using previous steps

**** SOTA NMT models
***** TODO download SOTA models from fairseq, start testing paraphrased samples on it and manually check out differences in results, see if this idea makes sense on a large scale
***** look for models that worked on WMT 17 en-de dataset and work from there
***** after manual checks, start thinking of semantic similarity measures on the target end, also possibly on the source side although we can assume that the SCPN makes quite good paraphrases
***** set up English and German SOTA parsers on local system

**** Rules-based approaches
***** TODO consider other ways of generating paraphrases -> perhaps rules based approaches employing logical rules
***** check if application of logic affects NMT models

**** Documentation
***** add documentation/acknowledgments to datasets and code, refactor major code used in SCPN to make it cleaner and better
***** add citations in readme as per general standard

*** Completed
***** DONE set up WMT 17 dev/test data and basic repo
      CLOSED: [2020-04-29 Wed 15:57]
