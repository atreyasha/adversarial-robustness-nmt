@article{michel2019evaluation,
  title={On evaluation of adversarial perturbations for sequence-to-sequence models},
  author={Michel, Paul and Li, Xian and Neubig, Graham and Pino, Juan Miguel},
  journal={arXiv preprint arXiv:1903.06620},
  year={2019}
}

@article{cheng2018towards,
  title={Towards robust neural machine translation},
  author={Cheng, Yong and Tu, Zhaopeng and Meng, Fandong and Zhai, Junjie and Liu, Yang},
  journal={arXiv preprint arXiv:1805.06130},
  year={2018}
}

@article{cheng2018seq2sick,
  title={Seq2sick: Evaluating the robustness of sequence-to-sequence models with adversarial examples},
  author={Cheng, Minhao and Yi, Jinfeng and Chen, Pin-Yu and Zhang, Huan and Hsieh, Cho-Jui},
  journal={arXiv preprint arXiv:1803.01128},
  year={2018}
}

@article{ebrahimi2017hotflip,
  title={Hotflip: White-box adversarial examples for text classification},
  author={Ebrahimi, Javid and Rao, Anyi and Lowd, Daniel and Dou, Dejing},
  journal={arXiv preprint arXiv:1712.06751},
  year={2017}
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in neural information processing systems},
  pages={5998--6008},
  year={2017}
}

@article{iyyer2018adversarial,
  title={Adversarial example generation with syntactically controlled paraphrase networks},
  author={Iyyer, Mohit and Wieting, John and Gimpel, Kevin and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:1804.06059},
  year={2018}
}

@article{kim2018teaching,
  title={Teaching Syntax by Adversarial Distraction},
  author={Kim, Juho and Malon, Christopher and Kadav, Asim},
  journal={arXiv preprint arXiv:1810.11067},
  year={2018}
}

@article{lei2018discrete,
  title={Discrete adversarial attacks and submodular optimization with applications to text classification},
  author={Lei, Qi and Wu, Lingfei and Chen, Pin-Yu and Dimakis, Alexandros G and Dhillon, Inderjit S and Witbrock, Michael},
  journal={arXiv preprint arXiv:1812.00151},
  year={2018}
}

@article{zhang2019paws,
  title={PAWS: Paraphrase adversaries from word scrambling},
  author={Zhang, Yuan and Baldridge, Jason and He, Luheng},
  journal={arXiv preprint arXiv:1904.01130},
  year={2019}
}

@inproceedings{ribeiro2018semantically,
  title={Semantically equivalent adversarial rules for debugging nlp models},
  author={Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  booktitle={Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  pages={856--865},
  year={2018}
}

@inproceedings{vaibhav2019improving,
  title={Improving robustness of machine translation with synthetic noise},
  author={Vaibhav, Vaibhav and Singh, Sumeet and Stewart, Craig and Neubig, Graham},
  booktitle={Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)},
  pages={1916--1920},
  year={2019}
}

@article{karpukhin2019training,
  title={Training on synthetic noise improves robustness to natural noise in machine translation},
  author={Karpukhin, Vladimir and Levy, Omer and Eisenstein, Jacob and Ghazvininejad, Marjan},
  journal={arXiv preprint arXiv:1902.01509},
  year={2019}
}

@article{wieting2017paranmt,
  title={Paranmt-50m: Pushing the limits of paraphrastic sentence embeddings with millions of machine translations},
  author={Wieting, John and Gimpel, Kevin},
  journal={arXiv preprint arXiv:1711.05732},
  year={2017}
}

@inproceedings{sennrich2013exploiting,
  title={Exploiting synergies between open resources for german dependency parsing, pos-tagging, and morphological analysis},
  author={Sennrich, Rico and Volk, Martin and Schneider, Gerold},
  booktitle={Proceedings of the International Conference Recent Advances in Natural Language Processing RANLP 2013},
  pages={601--609},
  year={2013}
}

@InProceedings{Kitaev-2018-SelfAttentive,
  author    = {Kitaev, Nikita and Klein, Dan},
  title     = {Constituency Parsing with a Self-Attentive Encoder},
  booktitle = {Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  month     = {July},
  year      = {2018},
  address   = {Melbourne, Australia},
  publisher = {Association for Computational Linguistics},
}

@article{Hegde-Numax,
  author={C. {Hegde} and A. C. {Sankaranarayanan} and W. {Yin} and R. G. {Baraniuk}},
  journal={IEEE Transactions on Signal Processing}, 
  title={NuMax: A Convex Approach for Learning Near-Isometric Linear Embeddings}, 
  year={2015},
  volume={63},
  number={22},
  pages={6109-6121}
}

@article{coxeter1961introduction,
  title={Introduction to geometry},
  author={Coxeter, Harold Scott Macdonald},
  year={1961},
  publisher={New York, London}
}

@article{freitag-bleu-paraphrase-references-2020,
  title = {BLEU might be Guilty but References are not Innocent},
  author = {Markus Freitag and David Grangier and Isaac Caswell},
  journal = {ArXiv},
  year = {2020},
  volume = {abs/2004.06063}
}

@inproceedings{ott2018scaling,
  title = {Scaling Neural Machine Translation},
  author = {Ott, Myle and Edunov, Sergey and Grangier, David and Auli, Michael},
  booktitle = {Proceedings of the Third Conference on Machine Translation (WMT)},
  year = 2018,
}

@article{ng2019facebook,
  title={Facebook FAIR's WMT19 News Translation Task Submission},
  author={Ng, Nathan and Yee, Kyra and Baevski, Alexei and Ott, Myle and Auli, Michael and Edunov, Sergey},
  journal={arXiv preprint arXiv:1907.06616},
  year={2019}
}

@InProceedings{pawsx2019emnlp,
  title = {PAWS-X: A Cross-lingual Adversarial Dataset for Paraphrase Identification},
  author = {Yang, Yinfei and Zhang, Yuan and Tar, Chris and Baldridge, Jason},
  booktitle = {Proc. of EMNLP},
  year = {2019}
}

@article{hu2020xtreme,
  author = {Junjie Hu and Sebastian Ruder and Aditya Siddhant and Graham Neubig and Orhan Firat
  and Melvin Johnson},
  title = {XTREME: A Massively Multilingual Multi-task Benchmark for Evaluating Cross-lingual 
  Generalization},
  journal = {CoRR},
  volume = {abs/2003.11080},
  year = {2020},
  archivePrefix = {arXiv},
  eprint = {2003.11080}
}

@article{conneau2019unsupervised,
  title={Unsupervised cross-lingual representation learning at scale},
  author={Conneau, Alexis and Khandelwal, Kartikay and Goyal, Naman and Chaudhary, Vishrav and Wenzek, Guillaume and Guzm{\'a}n, Francisco and Grave, Edouard and Ott, Myle and Zettlemoyer, Luke and Stoyanov, Veselin},
  journal={arXiv preprint arXiv:1911.02116},
  year={2019}
}

@article{cer2017semeval,
  title={Semeval-2017 task 1: Semantic textual similarity-multilingual and cross-lingual focused evaluation},
  author={Cer, Daniel and Diab, Mona and Agirre, Eneko and Lopez-Gazpio, Inigo and Specia, Lucia},
  journal={arXiv preprint arXiv:1708.00055},
  year={2017}
}

@inproceedings{papineni2002bleu,
  title={BLEU: a method for automatic evaluation of machine translation},
  author={Papineni, Kishore and Roukos, Salim and Ward, Todd and Zhu, Wei-Jing},
  booktitle={Proceedings of the 40th annual meeting of the Association for Computational Linguistics},
  pages={311--318},
  year={2002}
}

@inproceedings{denkowski2014meteor,
  title={Meteor universal: Language specific translation evaluation for any target language},
  author={Denkowski, Michael and Lavie, Alon},
  booktitle={Proceedings of the ninth workshop on statistical machine translation},
  pages={376--380},
  year={2014}
}

@inproceedings{popovic2015chrf,
  title={chrF: character n-gram F-score for automatic MT evaluation},
  author={Popovi{\'c}, Maja},
  booktitle={Proceedings of the Tenth Workshop on Statistical Machine Translation},
  pages={392--395},
  year={2015}
}

@article{fadaee2020unreasonable,
  title={The Unreasonable Volatility of Neural Machine Translation Models},
  author={Fadaee, Marzieh and Monz, Christof},
  journal={arXiv preprint arXiv:2005.12398},
  year={2020}
}

@article{zhang2019paws,
  title={PAWS: Paraphrase adversaries from word scrambling},
  author={Zhang, Yuan and Baldridge, Jason and He, Luheng},
  journal={arXiv preprint arXiv:1904.01130},
  year={2019}
}

@inproceedings{devlin-etal-2019-bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/N19-1423",
    doi = "10.18653/v1/N19-1423",
    pages = "4171--4186",
    abstract = "We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models (Peters et al., 2018a; Radford et al., 2018), BERT is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE score to 80.5 (7.7 point absolute improvement), MultiNLI accuracy to 86.7{\%} (4.6{\%} absolute improvement), SQuAD v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and SQuAD v2.0 Test F1 to 83.1 (5.1 point absolute improvement).",
}

@inproceedings{ott2019fairseq,
  title = {fairseq: A Fast, Extensible Toolkit for Sequence Modeling},
  author = {Myle Ott and Sergey Edunov and Alexei Baevski and Angela Fan and Sam Gross and Nathan Ng and David Grangier and Michael Auli},
  booktitle = {Proceedings of NAACL-HLT 2019: Demonstrations},
  year = {2019},
}

@article{sennrich2015neural,
  title={Neural machine translation of rare words with subword units},
  author={Sennrich, Rico and Haddow, Barry and Birch, Alexandra},
  journal={arXiv preprint arXiv:1508.07909},
  year={2015}
}

@inproceedings{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  booktitle={Advances in neural information processing systems},
  pages={5998--6008},
  year={2017}
}

@article{srivastava2014dropout,
  title={Dropout: a simple way to prevent neural networks from overfitting},
  author={Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  journal={The journal of machine learning research},
  volume={15},
  number={1},
  pages={1929--1958},
  year={2014},
  publisher={JMLR. org}
}

@article{kingma2014adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@article{pereyra2017regularizing,
  title={Regularizing neural networks by penalizing confident output distributions},
  author={Pereyra, Gabriel and Tucker, George and Chorowski, Jan and Kaiser, {\L}ukasz and Hinton, Geoffrey},
  journal={arXiv preprint arXiv:1701.06548},
  year={2017}
}

@article{Wolf2019HuggingFacesTS,
  title={HuggingFace's Transformers: State-of-the-art Natural Language Processing},
  author={Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and R'emi Louf and Morgan Funtowicz and Jamie Brew},
  journal={ArXiv},
  year={2019},
  volume={abs/1910.03771}
}
